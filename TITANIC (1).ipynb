{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf4bbb5b-84bd-4e75-bf6d-e08800fd6eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb9dbbd2-3590-4682-9b35-7580e2a6febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "PassengerId       0\n",
      "Survived          0\n",
      "Pclass            0\n",
      "Name              0\n",
      "Sex               0\n",
      "Age             263\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Ticket            0\n",
      "Fare              1\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('titanic dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98d58c9f-37bb-478a-9c1f-c119e5cd6403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PassengerId  Survived  Pclass  \\\n",
      "0               1         0       3   \n",
      "1               2         1       1   \n",
      "2               3         1       3   \n",
      "3               4         1       1   \n",
      "4               5         0       3   \n",
      "...           ...       ...     ...   \n",
      "1304         1305         0       3   \n",
      "1305         1306         1       1   \n",
      "1306         1307         0       3   \n",
      "1307         1308         0       3   \n",
      "1308         1309         0       3   \n",
      "\n",
      "                                                   Name     Sex   Age  SibSp  \\\n",
      "0                               Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1     Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                                Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3          Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                              Allen, Mr. William Henry    male  35.0      0   \n",
      "...                                                 ...     ...   ...    ...   \n",
      "1304                                 Spector, Mr. Woolf    male  28.0      0   \n",
      "1305                       Oliva y Ocana, Dona. Fermina  female  39.0      0   \n",
      "1306                       Saether, Mr. Simon Sivertsen    male  38.5      0   \n",
      "1307                                Ware, Mr. Frederick    male  28.0      0   \n",
      "1308                           Peter, Master. Michael J    male  28.0      1   \n",
      "\n",
      "      Parch              Ticket      Fare    Cabin Embarked  \n",
      "0         0           A/5 21171    7.2500  Unknown        S  \n",
      "1         0            PC 17599   71.2833      C85        C  \n",
      "2         0    STON/O2. 3101282    7.9250  Unknown        S  \n",
      "3         0              113803   53.1000     C123        S  \n",
      "4         0              373450    8.0500  Unknown        S  \n",
      "...     ...                 ...       ...      ...      ...  \n",
      "1304      0           A.5. 3236    8.0500  Unknown        S  \n",
      "1305      0            PC 17758  108.9000     C105        C  \n",
      "1306      0  SOTON/O.Q. 3101262    7.2500  Unknown        S  \n",
      "1307      0              359309    8.0500  Unknown        S  \n",
      "1308      1                2668   22.3583  Unknown        C  \n",
      "\n",
      "[1309 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#filling missing values\n",
    "\n",
    "# Create a dictionary with the fill values for each column\n",
    "fill_values = {\n",
    "    'Age': df['Age'].median(),\n",
    "    'Fare': df['Fare'].median(),\n",
    "    'Cabin': 'Unknown',\n",
    "    'Embarked': df['Embarked'].mode()[0]\n",
    "}\n",
    "\n",
    "# Apply fillna to the entire DataFrame using the dictionary\n",
    "df.fillna(value=fill_values, inplace=True)\n",
    "\n",
    "# Print the DataFrame after filling missing values\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e12d0160-626f-48b6-817e-561a3cf407b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97d88109-2930-471a-84a3-699d371a2fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Drop columns that are not useful for prediction\n",
    "df.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1, inplace=True)\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "df['Sex'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "# Drop rows with missing values (if any)\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c8ad318-94f7-4471-9eaf-c2b347e494e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9683bd6c-5cd5-4dd2-8a8d-a3cb01dea18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PassengerId  Pclass                                    Name     Sex  \\\n",
      "1148         1149       3                   Niklasson, Mr. Samuel    male   \n",
      "1049         1050       1                Borebank, Mr. John James    male   \n",
      "982           983       3                      Pedersen, Mr. Olaf    male   \n",
      "808           809       2                       Meyer, Mr. August    male   \n",
      "1195         1196       3       McCarthy, Miss. Catherine Katie\"\"  female   \n",
      "...           ...     ...                                     ...     ...   \n",
      "572           573       1        Flynn, Mr. John Irwin (\"Irving\")    male   \n",
      "140           141       3           Boulos, Mrs. Joseph (Sultana)  female   \n",
      "1182         1183       3  Daly, Miss. Margaret Marcella Maggie\"\"  female   \n",
      "312           313       2   Lahtinen, Mrs. William (Anna Sylfven)  female   \n",
      "199           200       2  Yrois, Miss. Henriette (\"Mrs Harbeck\")  female   \n",
      "\n",
      "       Age  SibSp  Parch    Ticket     Fare    Cabin Embarked  \n",
      "1148  28.0      0      0    363611   8.0500  Unknown        S  \n",
      "1049  42.0      0      0    110489  26.5500      D22        S  \n",
      "982   28.0      0      0    345498   7.7750  Unknown        S  \n",
      "808   39.0      0      0    248723  13.0000  Unknown        S  \n",
      "1195  28.0      0      0    383123   7.7500  Unknown        Q  \n",
      "...    ...    ...    ...       ...      ...      ...      ...  \n",
      "572   36.0      0      0  PC 17474  26.3875      E25        S  \n",
      "140   28.0      0      2      2678  15.2458  Unknown        C  \n",
      "1182  30.0      0      0    382650   6.9500  Unknown        Q  \n",
      "312   26.0      1      1    250651  26.0000  Unknown        S  \n",
      "199   24.0      0      0    248747  13.0000  Unknown        S  \n",
      "\n",
      "[262 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65265bf8-2236-4b9e-aba0-5ea3a0e40297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac5813df-b116-4e84-9ddc-da103b3d99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "with open('titanic.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21bf772b-3042-48fb-956f-ece009355821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.76323988  0.          0.         ...  0.          0.\n",
      "  -0.26566554]\n",
      " [ 0.60903427 -1.          0.         ...  0.          0.\n",
      "   0.50177029]\n",
      " [ 0.5046729   0.          0.         ...  0.          0.\n",
      "  -0.27707337]\n",
      " ...\n",
      " [ 0.81619938  0.         -1.         ...  0.          0.\n",
      "  -0.31129686]\n",
      " [-0.53894081 -0.5        -1.         ...  1.          1.\n",
      "   0.47895463]\n",
      " [-0.71495327 -0.5        -1.         ...  0.          0.\n",
      "  -0.0603246 ]]\n",
      "Accuracy: 0.8702290076335878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       159\n",
      "           1       0.85      0.82      0.83       103\n",
      "\n",
      "    accuracy                           0.87       262\n",
      "   macro avg       0.87      0.86      0.86       262\n",
      "weighted avg       0.87      0.87      0.87       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "print(X_test)\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0f01bb6-ddc0-4f6e-b8d1-c3f9766c3c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 6 features, but RandomForestClassifier is expecting 7 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example of making a prediction for a new passenger\u001b[39;00m\n\u001b[0;32m      2\u001b[0m new_passenger \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m70\u001b[39m]\n\u001b[0;32m      9\u001b[0m })\n\u001b[1;32m---> 11\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(new_passenger)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvival Prediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:905\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    885\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 905\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:947\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    945\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    946\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    950\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    642\u001b[0m     X,\n\u001b[0;32m    643\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    644\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    645\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    646\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    647\u001b[0m )\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 6 features, but RandomForestClassifier is expecting 7 features as input."
     ]
    }
   ],
   "source": [
    "# Example of making a prediction for a new passenger\n",
    "new_passenger = pd.DataFrame({\n",
    "    'Pclass': [1],\n",
    "    'Sex': [1],\n",
    "    'Age': [30],\n",
    "    'SibSp': [0],\n",
    "    'Parch': [0],\n",
    "    'Fare': [70]\n",
    "})\n",
    "\n",
    "prediction = model.predict(new_passenger)\n",
    "print(f'Survival Prediction: {prediction[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e982c-7e1e-4b2d-b275-026f9f93a779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
